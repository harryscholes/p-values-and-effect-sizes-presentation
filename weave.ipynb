{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â”Œ Info: Recompiling stale cache file /Users/harry/.julia/compiled/v1.1/StatsPlots/SiylL.ji for StatsPlots [f3b207a7-027a-5e70-b257-86293d7955fd]\n",
      "â”” @ Base loading.jl:1184\n"
     ]
    }
   ],
   "source": [
    "using EffectSizes, Random, HypothesisTests, StatsPlots, Statistics, Distributions\n",
    "\n",
    "const TTest = EqualVarianceTTest\n",
    "const c = get_color_palette(:auto, plot_color(:white), 3)\n",
    "\n",
    "default(:size, (500,300))\n",
    "default(:legend, false)\n",
    "\n",
    "function sampledata(;n, seed=1, Î”=0)\n",
    "    !isnothing(seed) && Random.seed!(seed)\n",
    "    randn(n), randn(n) .+ Î”\n",
    "end\n",
    "\n",
    "resample(xs) = xs[rand(1:length(xs), length(xs))]\n",
    "\n",
    "bootstrap(xs, ys, n=1000) = [pvalue(TTest(resample(xs), resample(ys))) for _ = 1:n]\n",
    "\n",
    "function confidenceinterval(xs; quantile=0.95)\n",
    "    lq = (1-quantile)/2 # two-tailedness\n",
    "    uq = quantile+lq\n",
    "    Distributions.quantile(xs, lq), Distributions.quantile(xs, uq)\n",
    "end\n",
    "\n",
    "function simulate(s::Integer; Î”, nboot)\n",
    "    es = EffectSize[]\n",
    "    ps = Float64[]\n",
    "    for _ = 1:nboot\n",
    "        xs, ys = sampledata(n=s, Î”=Î”, seed=nothing)\n",
    "        push!(es, EffectSize(xs, ys))\n",
    "        push!(ps, pvalue(EqualVarianceTTest(xs, ys)))\n",
    "    end\n",
    "    es, ps\n",
    "end\n",
    "\n",
    "function simulate(sizes::AbstractArray; Î”, nboot)\n",
    "    es, ps = collect.(zip(map(s->simulate(s, Î”=Î”, nboot=nboot), sizes)...))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# $P$ values and effect sizes\n",
    "\n",
    "# Time for $P$ values to P off?\n",
    "\n",
    "### Harry Scholes, @harryscholes\n",
    "\n",
    "---\n",
    "\n",
    "## Scientists rise up against statistical significance.\n",
    "\n",
    "https://www.nature.com/articles/d41586-019-00857-9\n",
    "\n",
    "Comment piece in Nature with over 800 signatories calling for urgent reform of hypothesis\n",
    "testing in scientific research.\n",
    "\n",
    "## We see this all the time, but what does it mean?\n",
    "\n",
    "$P < 0.05$\n",
    "\n",
    "## So, what are $P$ values?\n",
    "\n",
    "$P$ is the probability that the test statistic is equal to, or more extreme than, the\n",
    "observed test statistic when the null hypothesis is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hâ‚€ = randn(1000)\n",
    "histogram(Hâ‚€, xlabel=\"X\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = 2.1\n",
    "p = (1 + count(Hâ‚€ .â‰¥ obs)) / (1 + length(Hâ‚€))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $P$ values are a measure of how compatible a sample is with a hypothesis.\n",
    "\n",
    "Are these samples drawn from different distributions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = sampledata(n=10^3)\n",
    "\n",
    "histogram([xs, ys], Î±=.5, xlabel=\"X\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue(TTest(xs, ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about these samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = sampledata(n=10^3, seed=16)\n",
    "\n",
    "histogram([xs, ys], Î±=.5, xlabel=\"X\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue(TTest(xs, ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $P$ values are random variables.\n",
    "\n",
    "Let's do a simulation to demonstrate this:\n",
    "\n",
    "* Sample from a normal distribution with mean $\\mu = 0.5$\n",
    "* Perform a t-test of the hypothesis\n",
    "\n",
    "$H_0 : \\mu \\le \\mu{_0} $\n",
    "\n",
    "$H_a : \\mu > \\mu{_0} $\n",
    "\n",
    "* Repeat 10,000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Î¼  = 0.5  # sample mean\n",
    "Î¼â‚€ = 0    # population mean\n",
    "\n",
    "samples = [rand(Normal(Î¼), 10) for _ = 1:10^4]\n",
    "ttests = OneSampleTTest.(samples, Î¼â‚€)\n",
    "pvalues = pvalue.(ttests, tail=:right)\n",
    "\n",
    "histogram(pvalues, xlabel=\"P\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $P$ values are not a measure of the truth of a hypothesis.\n",
    "\n",
    "Let's also simulate this, but this time we'll sample from a normal distribution with mean $\\mu = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Î¼  = 0  # sample mean\n",
    "Î¼â‚€ = 0  # population mean\n",
    "\n",
    "samples = [rand(Normal(Î¼), 10) for _ = 1:10^4]\n",
    "ttests = OneSampleTTest.(samples, Î¼â‚€)\n",
    "pvalues = pvalue.(ttests, tail=:right)\n",
    "\n",
    "histogram(pvalues, xlabel=\"P\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the null hypothesis is true, $P$ values are uniformly distributed $U(0,1)$.\n",
    "\n",
    "##Â Misconceptions of $P$ values:\n",
    "\n",
    "* If $P > \\alpha$, you can never conclude that there is \"no difference\" or \"no association\".\n",
    "\n",
    "* If $P < \\alpha$, you can never accept the alternative hypothesis.\n",
    "\n",
    "## $P$ values conflate effect size and sample size.\n",
    "\n",
    "Let's compare large samples from two similar distributions. What's the $P$ value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = sampledata(n=10^5, Î”=0.01)\n",
    "\n",
    "pvalue(TTest(xs, ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P < 0.05$, so let's publish the results!\n",
    "\n",
    "Let's make the figure for the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram([xs, ys], Î±=.5, xlabel=\"X\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oh... ðŸ’©\n",
    "\n",
    "How confident are we that our result is significant? Confidence intervals can be assigned using bootstrap resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidenceinterval(bootstrap(xs, ys, 100), quantile=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay, so what do we mean by 'significance'?\n",
    "\n",
    "In reality, we do not _actually_ care if $P < 0.05$. What we really care about the effect size.\n",
    "\n",
    "For example, take a drug that extends lifespan with $P << 0.05$. Is it worth spending\n",
    "$2 billion to develop this drug if the effect size of the lifespan extension is one month?\n",
    "\n",
    "---\n",
    "\n",
    "##Â Effect size\n",
    "\n",
    "The effect size index is a dimensionless quantity.\n",
    "\n",
    "One formula is Cohen's $d$:\n",
    "\n",
    "$d = \\frac{m_A - m_B}{s}$\n",
    "\n",
    "where\n",
    "\n",
    "$s = \\sqrt{\\frac{(n_A - 1) s_A^2 + (n_B - 1) s_B^2}{n_A + n_B - 2}}$\n",
    "\n",
    "Effect | Effect size\n",
    ":---|---:\n",
    "Small | 0.2\n",
    "Medium | 0.5\n",
    "Large | 0.8\n",
    "\n",
    "## EffectSizes.jl\n",
    "\n",
    "https://github.com/harryscholes/EffectSizes.jl\n",
    "\n",
    "- Cohen's $d$\n",
    "- Hedge's $g$\n",
    "- Glass's $\\Delta$\n",
    "- Confidence intervals\n",
    "    - Normal\n",
    "    - Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation:\n",
    "# using Pkg\n",
    "# Pkg.add(\"EffectSizes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using EffectSizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = sampledata(n=10^4, seed=6)\n",
    "\n",
    "@show pvalue(TTest(xs, ys))\n",
    "histogram([xs, ys], Î±=.5, xlabel=\"X\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the effect size is and assign bootstrap confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EffectSize(xs, ys, 10^3, quantile=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to $P$ the result is significant, but according to $d$ there is no effect.\n",
    "\n",
    "## Large effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = sampledata(n=10^4, Î”=1)\n",
    "\n",
    "@show pvalue(TTest(xs, ys))\n",
    "@show confidenceinterval(bootstrap(xs, ys, 10^3), quantile=0.95)\n",
    "@show EffectSize(xs, ys, 10^3, quantile=0.95)\n",
    "histogram([xs, ys], Î±=.5, xlabel=\"X\", ylabel=\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of $P$ values and effect sizes\n",
    "\n",
    "Let's compare $P$ values and effect sizes for samples:\n",
    "* Drawn from similar distributions.\n",
    "* With different sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesizes = 10 .^ (1:6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es, ps = simulate(samplesizes, Î”=0.01, nboot=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(ps, xlabel=\"log10 sample size\", ylabel=\"P\", c=c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(map(x->effectsize.(x), es), xlabel=\"log10 sample size\", ylabel=\"d\", c=c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(map(x->mean(effectsize.(x)), es),\n",
    "        ribbon=(map(x->mean(lower.(confint.(x))), es) .* -1,\n",
    "                map(x->mean(upper.(confint.(x))), es)),\n",
    "        xlabel=\"log10 sample size\", ylabel=\"d\", c=c[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Retire significance, but still test hypotheses\n",
    "\n",
    "https://www.nature.com/articles/d41586-019-00972-7\n",
    "\n",
    ">Testing establishes whether there is an effect, and that helps to determine whether or not\n",
    "the magnitude needs to be estimated. â€¦ What happens when statistical testing is skipped and\n",
    "the null hypothesis is ignored? Well, noise would be interpreted as structural, and any\n",
    "differences between observations would be considered meaningful.\n",
    "\n",
    "## Further reading\n",
    "\n",
    "### $P$ values\n",
    "- Interpreting $P$ values https://www.nature.com/articles/nmeth.4210\n",
    "\n",
    "- $P$ values and the search for significance https://www.nature.com/articles/nmeth.4120\n",
    "\n",
    "- $P$ values are random variables https://www.tandfonline.com/doi/abs/10.1198/000313008X332421\n",
    "\n",
    "### Effect sizes\n",
    "- Statistical Power Analysis for the Behavioral Sciences http://www.utstat.toronto.edu/~brunner/oldclass/378f16/readings/CohenPower.pdf\n",
    "- Tutorials\n",
    "    - https://www.leeds.ac.uk/educol/documents/00002182.htm\n",
    "    - http://staff.bath.ac.uk/pssiw/stats2/page2/page14/page14.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
